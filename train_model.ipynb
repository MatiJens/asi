{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f786a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "positive_train: 100%|██████████| 3/3 [00:00<00:00, 11.26it/s]\n",
      "negative_train: 100%|██████████| 9/9 [00:00<00:00, 10.50it/s]\n",
      "positive_val: 100%|██████████| 2/2 [00:00<00:00, 12.59it/s]\n",
      "negative_val: 100%|██████████| 2/2 [00:00<00:00, 12.99it/s]\n",
      "positive_test: 100%|██████████| 1/1 [00:00<00:00, 44.38it/s]\n",
      "negative_test: 100%|██████████| 2/2 [00:00<00:00, 12.63it/s]\n",
      "Epoch 1: 100%|██████████| 169/169 [00:04<00:00, 38.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 0.2095 | Val AP: 0.9897\n",
      "--> Model saved (AP: 0.9897)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 169/169 [00:04<00:00, 34.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Loss: 0.0157 | Val AP: 0.9913\n",
      "--> Model saved (AP: 0.9913)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 169/169 [00:04<00:00, 40.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Loss: 0.0065 | Val AP: 0.9887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 169/169 [00:04<00:00, 40.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Loss: 0.0028 | Val AP: 0.9906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 169/169 [00:04<00:00, 37.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Loss: 0.0016 | Val AP: 0.9911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 169/169 [00:04<00:00, 35.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Loss: 0.0010 | Val AP: 0.9924\n",
      "--> Model saved (AP: 0.9924)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 169/169 [00:05<00:00, 30.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Loss: 0.0006 | Val AP: 0.9934\n",
      "--> Model saved (AP: 0.9934)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 169/169 [00:05<00:00, 33.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Loss: 0.0005 | Val AP: 0.9920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 169/169 [00:05<00:00, 29.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Loss: 0.0004 | Val AP: 0.9915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 169/169 [00:04<00:00, 34.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Loss: 0.0003 | Val AP: 0.9914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 169/169 [00:04<00:00, 35.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Loss: 0.0002 | Val AP: 0.9925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 169/169 [00:04<00:00, 35.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Loss: 0.0002 | Val AP: 0.9920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 169/169 [00:04<00:00, 35.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Loss: 0.0002 | Val AP: 0.9925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 169/169 [00:03<00:00, 45.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Loss: 0.0001 | Val AP: 0.9917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 169/169 [00:04<00:00, 40.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Loss: 0.0001 | Val AP: 0.9930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 169/169 [00:04<00:00, 33.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Loss: 0.0001 | Val AP: 0.9929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 169/169 [00:05<00:00, 28.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Loss: 0.0001 | Val AP: 0.9933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 169/169 [00:04<00:00, 37.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Loss: 0.0001 | Val AP: 0.9908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 169/169 [00:04<00:00, 38.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Loss: 0.0004 | Val AP: 0.9944\n",
      "--> Model saved (AP: 0.9944)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 169/169 [00:04<00:00, 37.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Loss: 0.0001 | Val AP: 0.9956\n",
      "--> Model saved (AP: 0.9956)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import average_precision_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATA_DIR = \"data\"\n",
    "MODEL_SAVE_PATH = os.path.join(DATA_DIR, \"esmc_bilstm_best.pth\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 20\n",
    "HIDDEN_DIM = 32\n",
    "DROPOUT = 0.1\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class ASMEmbeddingsDataset(Dataset):\n",
    "    def __init__(self, root_dir, split='train'):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        categories = {f'positive_{split}': 1.0, f'negative_{split}': 0.0}\n",
    "        \n",
    "        for folder_name, label_val in categories.items():\n",
    "            dir_path = os.path.join(root_dir, folder_name)\n",
    "            if not os.path.exists(dir_path):\n",
    "                print(f\"Missing folder: {dir_path}\")\n",
    "                continue\n",
    "            \n",
    "            shard_files = glob.glob(os.path.join(dir_path, \"*.pt\"))\n",
    "            for p in tqdm(shard_files, desc=folder_name):\n",
    "                try:\n",
    "                    shard_content = torch.load(p, map_location='cpu')\n",
    "                    for _, embedding in shard_content.items():\n",
    "                        self.data.append(embedding.float())\n",
    "                        self.labels.append(label_val)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error during loading file {p}: {e}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    embeddings, labels = zip(*batch)\n",
    "    padded_embeddings = pad_sequence(embeddings, batch_first=True, padding_value=0.0)\n",
    "    labels = torch.stack(labels)\n",
    "    return padded_embeddings, labels\n",
    "\n",
    "class ASMDetectorLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (hn, _) = self.lstm(x)\n",
    "        final_embedding = torch.cat((hn[-2], hn[-1]), dim=1)\n",
    "        x = self.dropout(final_embedding)\n",
    "        return self.sigmoid(self.fc(x)).squeeze(-1)\n",
    "\n",
    "train_dataset = ASMEmbeddingsDataset(DATA_DIR, split='train')\n",
    "val_dataset = ASMEmbeddingsDataset(DATA_DIR, split='val')\n",
    "test_dataset = ASMEmbeddingsDataset(DATA_DIR, split='test')\n",
    "\n",
    "if len(train_dataset) > 0:\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn) if len(test_dataset) > 0 else None\n",
    "    INPUT_DIM = train_dataset[0][0].shape[-1]\n",
    "    \n",
    "    model = ASMDetectorLSTM(INPUT_DIM, HIDDEN_DIM, DROPOUT).to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    best_val_ap = 0.0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for X, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(X), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        val_preds, val_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for X, y in val_loader:\n",
    "                preds = model(X.to(DEVICE)).cpu().numpy()\n",
    "                val_preds.extend(preds)\n",
    "                val_targets.extend(y.numpy())\n",
    "        \n",
    "        val_ap = average_precision_score(val_targets, val_preds)\n",
    "        print(f\"Epoch {epoch+1} | Loss: {train_loss/len(train_loader):.4f} | Val AP: {val_ap:.4f}\")\n",
    "\n",
    "        if val_ap > best_val_ap:\n",
    "            best_val_ap = val_ap\n",
    "            torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "            print(f\"--> Model saved (AP: {best_val_ap:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47eec7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: FPR < 0.001 (0.1%)\n",
      "\n",
      "Threshold:    0.001710\n",
      "Recall (TPR): 80.11%\n",
      "FPR:          0.0000%\n",
      "TP / Pos:     145 / 181\n",
      "FP / Neg:     0 / 874\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate_at_fixed_fpr(model, dataloader, target_fpr=1e-3):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    all_scores = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            scores = model(X.to(device)).cpu().numpy()\n",
    "            targets = y.numpy()\n",
    "            all_scores.extend(scores)\n",
    "            all_targets.extend(targets)\n",
    "            \n",
    "    all_scores = np.array(all_scores)\n",
    "    all_targets = np.array(all_targets)\n",
    "    \n",
    "    desc_score_indices = np.argsort(all_scores)[::-1]\n",
    "    all_scores = all_scores[desc_score_indices]\n",
    "    all_targets = all_targets[desc_score_indices]\n",
    "    \n",
    "    negatives = (all_targets == 0)\n",
    "    positives = (all_targets == 1)\n",
    "    \n",
    "    n_neg = negatives.sum()\n",
    "    n_pos = positives.sum()\n",
    "    \n",
    "    fps = np.cumsum(negatives)\n",
    "    tps = np.cumsum(positives)\n",
    "    \n",
    "    calculated_fprs = fps / n_neg\n",
    "    \n",
    "    valid_indices = np.where(calculated_fprs <= target_fpr)[0]\n",
    "    \n",
    "    if len(valid_indices) == 0:\n",
    "        print(f\"Failed to achieve FPR <= {target_fpr}. The lowest possible FPR is {calculated_fprs[0]:.4f}\")\n",
    "        return\n",
    "        \n",
    "    cutoff_idx = valid_indices[-1]\n",
    "    best_threshold = all_scores[cutoff_idx]\n",
    "    \n",
    "    recall = tps[cutoff_idx] / n_pos\n",
    "    actual_fpr = calculated_fprs[cutoff_idx]\n",
    "    \n",
    "    print(f\"Target: FPR < {target_fpr} ({target_fpr*100}%)\\n\")\n",
    "    print(f\"Threshold:    {best_threshold:.6f}\")\n",
    "    print(f\"Recall (TPR): {recall*100:.2f}%\")\n",
    "    print(f\"FPR:          {actual_fpr*100:.4f}%\")\n",
    "    print(f\"TP / Pos:     {int(tps[cutoff_idx])} / {n_pos}\")\n",
    "    print(f\"FP / Neg:     {int(fps[cutoff_idx])} / {n_neg}\")\n",
    "\n",
    "if 'model' in locals() and 'test_loader' in locals() and test_loader is not None:\n",
    "    model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "    evaluate_at_fixed_fpr(model, test_loader, target_fpr=0.001)\n",
    "else:\n",
    "    print(\"Skipping evaluation: test_loader not defined or empty.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
